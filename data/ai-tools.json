{
  "metadata": {
    "lastUpdated": "2025-01-27T10:30:00Z",
    "totalTools": 65,
    "activeTools": 62,
    "categories": 6
  },
  "categories": {
    "google_ai": {
      "name": "Google AI Tools",
      "description": "Google AI tools and services",
      "tools": [
        {
          "id": "gemini",
          "name": "Google Gemini",
          "description": "Google's multimodal AI model supporting text, image, and code processing",
          "url": "https://ai.google.dev/",
          "category": "llm",
          "capabilities": ["text", "vision", "code", "reasoning"],
          "pricing": "free_tier_available",
          "freeQuota": {
            "requests": "60 requests/minute",
            "tokens": "1M input tokens/month",
            "models": "Gemini 1.5 Flash"
          },
          "lastUpdate": "2024-01-15",
          "newFeatures": [
            "Gemini 1.5 Pro extended context window to 2M tokens",
            "Improved code understanding capabilities",
            "Enhanced multilingual support"
          ],
          "status": {
            "health": "active",
            "lastChecked": "2024-01-15T09:30:00Z",
            "responseTime": 234
          },
          "blogUrl": "https://blog.google/technology/ai/",
          "tags": ["llm", "multimodal", "api", "free-tier"]
        },
        {
          "id": "ai-studio",
          "name": "Google AI Studio",
          "description": "Google's AI development platform for testing and deploying Gemini models",
          "url": "https://aistudio.google.com/",
          "category": "development_platform",
          "capabilities": ["prompt_engineering", "model_tuning", "api_testing"],
          "pricing": "free",
          "lastUpdate": "2024-01-12",
          "newFeatures": [
            "Added batch processing functionality",
            "Improved Prompt debugging tools",
            "Support for custom function calls"
          ],
          "status": {
            "health": "active",
            "lastChecked": "2024-01-15T09:31:00Z",
            "responseTime": 189
          },
          "tags": ["development", "prompt-engineering", "testing", "free"]
        }
      ]
    },
    "workflow_automation": {
      "name": "Workflow Automation",
      "description": "AI tools for automating workflows and tasks",
      "tools": [
        {
          "id": "n8n",
          "name": "n8n",
          "description": "Open-source workflow automation platform with 400+ integrations",
          "url": "https://n8n.io/",
          "category": "automation",
          "deployment": ["cloud", "self-hosted"],
          "integrations": 400,
          "lastRelease": "1.25.0",
          "newFeatures": [
            "AI Agent node support",
            "Enhanced error handling mechanisms",
            "New OpenAI and Anthropic integrations"
          ],
          "pricing": "freemium",
          "freeQuota": {
            "workflows": "Unlimited (self-hosted)",
            "executions": "5000/month (cloud)",
            "users": "1 user (cloud free)"
          },
          "status": {
            "health": "active",
            "lastChecked": "2024-01-15T09:32:00Z",
            "githubStars": 42000
          },
          "repository": "https://github.com/n8n-io/n8n",
          "tags": ["automation", "workflow", "open-source", "integrations"]
        },
        {
          "id": "zapier",
          "name": "Zapier",
          "description": "Automation platform connecting different applications",
          "url": "https://zapier.com/",
          "category": "automation",
          "integrations": 5000,
          "pricing": "freemium",
          "freeQuota": {
            "zaps": "5 Zaps",
            "tasks": "100 tasks/month"
          },
          "lastUpdate": "2024-01-14",
          "newFeatures": [
            "AI-driven Zap suggestions",
            "New ChatGPT and Claude integrations",
            "Improved conditional logic"
          ],
          "status": {
            "health": "active",
            "lastChecked": "2024-01-15T09:33:00Z",
            "responseTime": 345
          },
          "tags": ["automation", "saas", "integrations", "no-code"]
        }
      ]
    },
    "ai_platforms": {
      "name": "AI Development Platforms", 
      "description": "Platforms for building and deploying AI applications",
      "tools": [
        {
          "id": "dify",
          "name": "Dify",
          "description": "Open-source LLMOps platform for building AI applications and workflows",
          "url": "https://dify.ai/",
          "category": "llmops",
          "features": ["workflow", "agent", "chatbot", "knowledge_base"],
          "deployment": ["cloud", "docker", "source"],
          "lastUpdate": "2024-01-14",
          "githubStars": 45000,
          "newFeatures": [
            "Added RAG enhancement features",
            "Support for multi-model parallel inference",
            "Improved Agent collaboration capabilities"
          ],
          "pricing": "open_source",
          "cloudPricing": "pay_as_you_go",
          "status": {
            "health": "active",
            "lastChecked": "2024-01-15T09:34:00Z"
          },
          "repository": "https://github.com/langgenius/dify",
          "tags": ["llmops", "open-source", "workflow", "rag"]
        },
        {
          "id": "langsmith",
          "name": "LangSmith",
          "description": "LangChain's official LLM application development and monitoring platform",
          "url": "https://smith.langchain.com/",
          "category": "llmops",
          "features": ["debugging", "testing", "monitoring", "dataset_management"],
          "pricing": "freemium",
          "freeQuota": {
            "traces": "5000 traces/month",
            "datasets": "Unlimited",
            "users": "1 user"
          },
          "lastUpdate": "2024-01-13",
          "newFeatures": [
            "Added A/B testing functionality",
            "Improved performance analysis tools",
            "Support for custom evaluation metrics"
          ],
          "status": {
            "health": "active",
            "lastChecked": "2024-01-15T09:35:00Z",
            "responseTime": 456
          },
          "tags": ["llmops", "langchain", "monitoring", "testing"]
        }
      ]
    },
    "image_generation": {
      "name": "Image Generation Tools",
      "description": "AI image generation and editing tools",
      "tools": [
        {
          "id": "comfyui",
          "name": "ComfyUI",
          "description": "Node-based Stable Diffusion GUI with powerful workflow capabilities",
          "url": "https://github.com/comfyanonymous/ComfyUI",
          "category": "image_generation",
          "features": ["node_workflow", "custom_nodes", "api", "model_management"],
          "installation": ["pip", "docker", "portable"],
          "communityNodes": 2000,
          "lastUpdate": "2024-01-14",
          "newFeatures": [
            "Added FLUX model support",
            "Improved memory management",
            "WebUI interface optimization"
          ],
          "pricing": "free_open_source",
          "status": {
            "health": "active",
            "lastChecked": "2024-01-15T09:36:00Z"
          },
          "githubStars": 38000,
          "repository": "https://github.com/comfyanonymous/ComfyUI",
          "tags": ["stable-diffusion", "image-generation", "workflow", "open-source"]
        },
        {
          "id": "automatic1111",
          "name": "AUTOMATIC1111",
          "description": "Most popular Stable Diffusion WebUI",
          "url": "https://github.com/AUTOMATIC1111/stable-diffusion-webui",
          "category": "image_generation",
          "features": ["webui", "extensions", "model_training", "img2img"],
          "installation": ["git", "docker"],
          "extensions": 1500,
          "lastUpdate": "2024-01-12",
          "newFeatures": [
            "Support for SDXL Turbo",
            "Added batch processing functionality",
            "Improved extension manager"
          ],
          "pricing": "free_open_source",
          "status": {
            "health": "active",
            "lastChecked": "2024-01-15T09:37:00Z"
          },
          "githubStars": 135000,
          "repository": "https://github.com/AUTOMATIC1111/stable-diffusion-webui",
          "tags": ["stable-diffusion", "webui", "extensions", "open-source"]
        }
      ]
    },
    "local_llm": {
      "name": "Local LLM Tools",
      "description": "Tools for running large language models locally",
      "tools": [
        {
          "id": "ollama",
          "name": "Ollama",
          "description": "Simplified tool for running local LLMs, supports multiple open-source models",
          "url": "https://ollama.com/",
          "category": "local_inference",
          "models_supported": ["llama3", "codellama", "mistral", "gemma", "phi3"],
          "platforms": ["macOS", "Linux", "Windows"],
          "gpu_support": true,
          "last_release": "0.1.45",
          "new_models": [
            "Llama 3.1 70B",
            "Phi-3 Medium",
            "CodeGemma 7B"
          ],
          "pricing": "free_open_source",
          "status": {
            "health": "active",
            "lastChecked": "2024-01-15T09:38:00Z"
          },
          "github_url": "https://github.com/ollama/ollama",
          "githubStars": 75000,
          "tags": ["local-llm", "cli", "docker", "open-source"]
        },
        {
          "id": "lm-studio",
          "name": "LM Studio",
          "description": "Desktop GUI application for running local LLMs",
          "url": "https://lmstudio.ai/",
          "category": "local_inference",
          "platforms": ["macOS", "Windows", "Linux"],
          "features": ["gui", "model_discovery", "chat_interface", "api_server"],
          "pricing": "free",
          "lastUpdate": "2024-01-13",
          "newFeatures": [
            "Added model search functionality",
            "Improved conversation interface",
            "Support for multimodal models"
          ],
          "status": {
            "health": "active",
            "lastChecked": "2024-01-15T09:39:00Z",
            "responseTime": 123
          },
          "tags": ["local-llm", "gui", "desktop", "chat"]
        }
      ]
    },
    "inference_apis": {
      "name": "Free LLM Inference APIs",
      "description": "Free and trial API platforms providing LLM inference services",
      "tools": [
        {
          "id": "openrouter",
          "name": "OpenRouter",
          "description": "Unified API for accessing multiple LLM providers with free tier",
          "url": "https://openrouter.ai/",
          "category": "api_aggregator",
          "pricing": "freemium",
          "freeQuota": {
            "requests": "20 requests/minute, 50 requests/day",
            "extended": "1000 requests/day with $10 lifetime topup"
          },
          "models": ["DeepSeek R1", "DeepSeek V3", "Llama 3.3 70B", "Mistral Large", "Claude 3.5 Sonnet", "GPT-4o", "Phi-4"],
          "features": ["model_routing", "unified_api", "cost_optimization"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:00:00Z",
            "responseTime": 450
          },
          "tags": ["api", "aggregator", "free-tier", "multiple-models"]
        },
        {
          "id": "google-ai-studio",
          "name": "Google AI Studio",
          "description": "Free access to Gemini models with generous quotas",
          "url": "https://aistudio.google.com/",
          "category": "free_provider",
          "pricing": "free",
          "freeQuota": {
            "requests": "15 requests/minute",
            "tokens": "1M tokens/day for Gemini 1.5 Flash"
          },
          "models": ["Gemini 1.5 Pro", "Gemini 1.5 Flash", "Gemini 2.0 Flash"],
          "features": ["multimodal", "long_context", "function_calling"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:01:00Z",
            "responseTime": 320
          },
          "tags": ["google", "gemini", "free", "multimodal"]
        },
        {
          "id": "nvidia-nim",
          "name": "NVIDIA NIM",
          "description": "Free inference for NVIDIA-optimized models",
          "url": "https://build.nvidia.com/",
          "category": "free_provider",
          "pricing": "free",
          "freeQuota": {
            "requests": "1000 requests/month per model"
          },
          "models": ["Llama 3.1 70B", "Mistral Large", "Nemotron-4 340B", "CodeLlama 70B"],
          "features": ["optimized_inference", "enterprise_ready", "multiple_models"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:02:00Z",
            "responseTime": 280
          },
          "tags": ["nvidia", "optimized", "enterprise", "free-tier"]
        },
        {
          "id": "mistral-platform",
          "name": "Mistral La Plateforme",
          "description": "Free tier for Mistral AI models",
          "url": "https://console.mistral.ai/",
          "category": "free_provider",
          "pricing": "freemium",
          "freeQuota": {
            "credits": "$5 free credits"
          },
          "models": ["Mistral Large", "Mistral Nemo", "Codestral", "Pixtral"],
          "features": ["function_calling", "json_mode", "multimodal"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:03:00Z",
            "responseTime": 380
          },
          "tags": ["mistral", "free-credits", "function-calling", "json"]
        },
        {
          "id": "huggingface-inference",
          "name": "HuggingFace Inference API",
          "description": "Free inference for thousands of open-source models",
          "url": "https://huggingface.co/inference-api",
          "category": "free_provider",
          "pricing": "freemium",
          "freeQuota": {
            "requests": "Rate limited per model"
          },
          "models": ["Meta-Llama models", "Mistral models", "CodeLlama", "Falcon", "BLOOM"],
          "features": ["open_source_models", "community_driven", "easy_integration"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:04:00Z",
            "responseTime": 520
          },
          "tags": ["huggingface", "open-source", "community", "free"]
        },
        {
          "id": "cerebras",
          "name": "Cerebras Inference",
          "description": "Ultra-fast inference with free tier",
          "url": "https://inference.cerebras.ai/",
          "category": "free_provider",
          "pricing": "freemium",
          "freeQuota": {
            "tokens": "30M tokens/month"
          },
          "models": ["Llama 3.1 70B", "Llama 3.1 8B"],
          "features": ["ultra_fast", "high_throughput", "optimized_hardware"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:05:00Z",
            "responseTime": 150
          },
          "tags": ["cerebras", "fast", "high-throughput", "free-tier"]
        },
        {
          "id": "groq",
          "name": "Groq",
          "description": "Lightning-fast LLM inference with free tier",
          "url": "https://console.groq.com/",
          "category": "free_provider",
          "pricing": "freemium",
          "freeQuota": {
            "requests": "14,400 requests/day",
            "tokens": "Rate limited per model"
          },
          "models": ["Llama 3.1 70B", "Llama 3.1 8B", "Mixtral 8x7B", "Gemma 7B"],
          "features": ["ultra_fast", "low_latency", "high_performance"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:06:00Z",
            "responseTime": 120
          },
          "tags": ["groq", "ultra-fast", "low-latency", "free-tier"]
        },
        {
          "id": "together-free",
          "name": "Together AI (Free)",
          "description": "Free tier for open-source model inference",
          "url": "https://api.together.xyz/",
          "category": "free_provider",
          "pricing": "freemium",
          "freeQuota": {
            "credits": "$1 with payment method"
          },
          "models": ["Llama 3.1 405B", "Llama 3.1 70B", "Qwen2.5 72B", "DeepSeek V3"],
          "features": ["large_models", "open_source", "research_friendly"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:07:00Z",
            "responseTime": 400
          },
          "tags": ["together", "large-models", "research", "trial-credits"]
        },
        {
          "id": "cohere-free",
          "name": "Cohere (Free Trial)",
          "description": "Free trial for Cohere's Command models",
          "url": "https://cohere.com/",
          "category": "trial_provider",
          "pricing": "trial",
          "freeQuota": {
            "credits": "Free trial credits"
          },
          "models": ["Command R+", "Command R", "Embed v3"],
          "features": ["rag_optimized", "enterprise_ready", "embeddings"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:08:00Z",
            "responseTime": 350
          },
          "tags": ["cohere", "command", "rag", "trial"]
        },
        {
          "id": "github-models",
          "name": "GitHub Models",
          "description": "Free access to models through GitHub",
          "url": "https://github.com/marketplace/models",
          "category": "free_provider",
          "pricing": "free",
          "freeQuota": {
            "requests": "Rate limited per model"
          },
          "models": ["GPT-4o", "Claude 3.5 Sonnet", "Llama 3.1", "Phi-3"],
          "features": ["github_integration", "multiple_providers", "developer_friendly"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:09:00Z",
            "responseTime": 380
          },
          "tags": ["github", "integration", "developer", "free"]
        },
        {
          "id": "cloudflare-workers-ai",
          "name": "Cloudflare Workers AI",
          "description": "Serverless AI inference with free tier",
          "url": "https://developers.cloudflare.com/workers-ai/",
          "category": "free_provider",
          "pricing": "freemium",
          "freeQuota": {
            "neurons": "10,000 neurons/day"
          },
          "models": ["Llama 3.3 70B", "Llama 3.2 11B Vision", "DeepSeek R1 Distill", "Qwen QwQ 32B", "Mistral 7B"],
          "features": ["serverless", "edge_computing", "low_latency", "global_deployment"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:10:00Z",
            "responseTime": 200
          },
          "tags": ["cloudflare", "serverless", "edge", "free-tier"]
        },
        {
          "id": "google-vertex-ai",
          "name": "Google Cloud Vertex AI",
          "description": "Free preview access to latest models",
          "url": "https://cloud.google.com/vertex-ai",
          "category": "free_provider",
          "pricing": "free_preview",
          "freeQuota": {
            "requests": "Various limits per model during preview"
          },
          "models": ["Gemini 2.5 Pro", "Llama 3.2 90B Vision", "Llama 3.1 70B", "DeepSeek R1"],
          "features": ["enterprise_ready", "multimodal", "latest_models"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:11:00Z",
            "responseTime": 320
          },
          "tags": ["google-cloud", "enterprise", "preview", "multimodal"]
        },
        {
          "id": "fireworks",
          "name": "Fireworks AI",
          "description": "Fast inference with $1 free credits",
          "url": "https://fireworks.ai/",
          "category": "trial_provider",
          "pricing": "trial",
          "freeQuota": {
            "credits": "$1 free credits"
          },
          "models": ["Llama 3.1 405B", "Mixtral 8x22B", "CodeLlama 34B"],
          "features": ["fast_inference", "open_models", "developer_friendly"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:12:00Z",
            "responseTime": 250
          },
          "tags": ["fireworks", "fast", "trial-credits", "open-models"]
        },
        {
          "id": "unify",
          "name": "Unify",
          "description": "Router to multiple providers with $5 trial credits",
          "url": "https://unify.ai/",
          "category": "trial_provider",
          "pricing": "trial",
          "freeQuota": {
            "credits": "$5 with payment method"
          },
          "models": ["Routes to OpenAI, Anthropic, Google, Mistral, and more"],
          "features": ["provider_routing", "cost_optimization", "unified_api"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:13:00Z",
            "responseTime": 380
          },
          "tags": ["router", "multiple-providers", "optimization", "trial"]
        },
        {
          "id": "hyperbolic",
          "name": "Hyperbolic",
          "description": "High-performance inference with $1 trial credits",
          "url": "https://hyperbolic.xyz/",
          "category": "trial_provider",
          "pricing": "trial",
          "freeQuota": {
            "credits": "$1 trial credits"
          },
          "models": ["DeepSeek V3", "Llama 3.3 70B", "Qwen2.5 72B", "Pixtral 12B"],
          "features": ["high_performance", "latest_models", "competitive_pricing"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:14:00Z",
            "responseTime": 280
          },
          "tags": ["hyperbolic", "performance", "latest", "trial"]
        },
        {
          "id": "sambanova",
          "name": "SambaNova Cloud",
          "description": "Fast inference with $5 free credits for 3 months",
          "url": "https://cloud.sambanova.ai/",
          "category": "trial_provider",
          "pricing": "trial",
          "freeQuota": {
            "credits": "$5 for 3 months"
          },
          "models": ["Llama 3.3 70B", "DeepSeek R1", "Qwen3-32B"],
          "features": ["fast_inference", "enterprise_ready", "latest_models"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:15:00Z",
            "responseTime": 220
          },
          "tags": ["sambanova", "enterprise", "trial-credits", "fast"]
        },
        {
          "id": "scaleway",
          "name": "Scaleway Generative APIs",
          "description": "1M free tokens for European users",
          "url": "https://www.scaleway.com/en/generative-apis/",
          "category": "free_provider",
          "pricing": "freemium",
          "freeQuota": {
            "tokens": "1,000,000 free tokens"
          },
          "models": ["Llama 3.3 70B", "Mistral Small", "Gemma 3 27B", "DeepSeek R1 Distill"],
          "features": ["european_provider", "gdpr_compliant", "generous_quota"],
          "status": {
            "health": "active",
            "lastChecked": "2025-01-27T09:16:00Z",
            "responseTime": 300
          },
          "tags": ["scaleway", "european", "gdpr", "generous-quota"]
        },
        {
          "id": "openai",
          "name": "OpenAI API",
          "description": "GPT series models official API service",
          "url": "https://openai.com/api/",
          "models": ["gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo", "dall-e-3"],
          "pricing": "pay_per_use",
          "free_credits": "$5",
          "rate_limits": "10,000 RPM (Tier 1)",
          "recent_updates": [
            "GPT-4o model release",
            "Reduced GPT-4 Turbo pricing",
            "Added structured output functionality"
          ],
          "status": {
            "health": "active",
            "lastChecked": "2024-01-15T09:40:00Z",
            "responseTime": 567
          },
          "status_page": "https://status.openai.com/",
          "tags": ["gpt", "api", "multimodal", "commercial"]
        },
        {
          "id": "anthropic",
          "name": "Anthropic Claude API",
          "description": "Claude series models official API service",
          "url": "https://www.anthropic.com/api/",
          "models": ["claude-3-5-sonnet", "claude-3-opus", "claude-3-haiku"],
          "pricing": "pay_per_use",
          "free_credits": "$5",
          "rate_limits": "Varies by model",
          "recent_updates": [
            "Claude 3.5 Sonnet release",
            "Improved tool usage capabilities",
            "Extended context window to 200K"
          ],
          "status": {
            "health": "active",
            "lastChecked": "2024-01-15T09:41:00Z", 
            "responseTime": 432
          },
          "tags": ["claude", "api", "reasoning", "commercial"]
        }
      ]
    }
  }
} 